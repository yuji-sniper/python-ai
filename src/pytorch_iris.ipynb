{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.6773030956586202\n",
      "val_accuracy: tensor(0.7667)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 乱数のシードを設定\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# irisデータセットの読み込み\n",
    "iris = load_iris()\n",
    "\n",
    "# 入力値と目標値を抽出\n",
    "x = iris.data\n",
    "t = iris.target\n",
    "\n",
    "# Tensorに変換\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "t = torch.tensor(t, dtype=torch.int64)\n",
    "\n",
    "# 入力値と目標値をまとめる\n",
    "# （[[[入力値1, 入力値2, ...], 目標値1], [[入力値1, 入力値2, ...], 目標値2], ...]）\n",
    "dataset = torch.utils.data.TensorDataset(x, t)\n",
    "\n",
    "# データセット分割\n",
    "# 60%:学習用, 20%:検証用, 20%:テスト用\n",
    "n_train = int(len(dataset) * 0.6)\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# ミニバッチに分割\n",
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "# 4→4→3のニューラルネットワーク\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "    \n",
    "    # 順伝播\n",
    "    def forward(self, x):\n",
    "        # 第1層\n",
    "        h = self.fc1(x) # 線形変換\n",
    "        h = F.relu(h) # 活性化関数\n",
    "        # 第2層\n",
    "        h = self.fc2(h) # 線形変換\n",
    "        return h\n",
    "\n",
    "# エポック数（学習回数）\n",
    "max_epoch = 1\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Net().to(device)\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for batch in train_loader:\n",
    "        # ミニバッチの取得\n",
    "        x, t = batch\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        \n",
    "        # 順伝播\n",
    "        y = net(x)\n",
    "        \n",
    "        # 誤差の計算\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        # print('loss:', loss)\n",
    "        \n",
    "        # 正解率の計算\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        accracy = torch.mean((y_label == t).float())\n",
    "        # print('accuracy:', accracy)\n",
    "        \n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 逆伝播\n",
    "        loss.backward()\n",
    "        \n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "\n",
    "# 検証\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    total_accracy = 0\n",
    "    for batch in val_loader:\n",
    "        x, t = batch\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        y = net(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        total_loss += loss.item()\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        total_accracy += torch.mean((y_label == t).float())\n",
    "    n = len(val_loader)\n",
    "    print('val_loss:', total_loss / n)\n",
    "    print('val_accuracy:', total_accracy / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 20    \n",
      "1 | fc2  | Linear | 15    \n",
      "--------------------------------\n",
      "35        Trainable params\n",
      "0         Non-trainable params\n",
      "35        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 9/9 [00:00<00:00, 96.39it/s, v_num=26, train_loss_step=0.379, train_acc_step=1.000, val_loss_step=0.409, val_acc_step=0.900, val_loss_epoch=0.465, val_acc_epoch=0.933, train_loss_epoch=0.397, train_acc_epoch=0.967] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 9/9 [00:00<00:00, 79.43it/s, v_num=26, train_loss_step=0.379, train_acc_step=1.000, val_loss_step=0.409, val_acc_step=0.900, val_loss_epoch=0.465, val_acc_epoch=0.933, train_loss_epoch=0.397, train_acc_epoch=0.967]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspaces/python/src/lightning_logs/version_26/checkpoints/epoch=29-step=270.ckpt\n",
      "Loaded model weights from the checkpoint at /workspaces/python/src/lightning_logs/version_26/checkpoints/epoch=29-step=270.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 43.93it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.9666666388511658\n",
      "     test_loss_epoch        0.42295554280281067\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.42295554280281067,\n",
       "  'test_acc_epoch': 0.9666666388511658}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 乱数のシードを設定\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# irisデータセットの読み込み\n",
    "iris = load_iris()\n",
    "\n",
    "# 入力値と目標値を抽出\n",
    "x = iris.data\n",
    "t = iris.target\n",
    "\n",
    "# Tensorに変換\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "t = torch.tensor(t, dtype=torch.int64)\n",
    "\n",
    "# 入力値と目標値をまとめる\n",
    "# （[[[入力値1, 入力値2, ...], 目標値1], [[入力値1, 入力値2, ...], 目標値2], ...]）\n",
    "dataset = torch.utils.data.TensorDataset(x, t)\n",
    "\n",
    "# データセット分割\n",
    "# 60%:学習用, 20%:検証用, 20%:テスト用\n",
    "n_train = int(len(dataset) * 0.6)\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# ミニバッチに分割\n",
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "# 4→4→3のニューラルネットワーク\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "    \n",
    "    # 順伝播\n",
    "    def forward(self, x):\n",
    "        # 第1層\n",
    "        h = self.fc1(x) # 線形変換\n",
    "        h = F.relu(h) # 活性化関数\n",
    "        # 第2層\n",
    "        h = self.fc2(h) # 線形変換\n",
    "        return h\n",
    "    \n",
    "    # 学習データの損失関数\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    # 検証データの損失関数\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    # テストデータの損失関数\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self.step(batch)\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def step(self, batch):\n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        acc = accuracy(y_label, t, 'multiclass', num_classes=3)\n",
    "        return loss, acc\n",
    "    \n",
    "    # 最適化手法\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "\n",
    "# pl.seed_everything(0)\n",
    "\n",
    "# 学習の実行\n",
    "net = Net()\n",
    "trainer = pl.Trainer(max_epochs=30, deterministic=True)\n",
    "trainer.fit(net, train_loader, val_loader)\n",
    "trainer.callback_metrics\n",
    "\n",
    "# テスト\n",
    "trainer.test(dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
